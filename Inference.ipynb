{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Forecasting without Sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "1. [Setup](#toc1_)    \n",
    "2. [Model](#toc2_)    \n",
    "2.1. [1 Hidden layer](#toc2_1_)    \n",
    "2.2. [Multiple Hidden layers](#toc2_2_)    \n",
    "3. [Functions](#toc3_)    \n",
    "3.1. [Prepare Data](#toc3_1_)    \n",
    "3.2. [Train & Evaluate](#toc3_2_)    \n",
    "3.3. [Load Data & Predict](#toc3_3_)    \n",
    "3.4. [Predict](#toc3_4_)    \n",
    "4. [Hyperparameter tuning](#toc4_)    \n",
    "5. [User Call](#toc5_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=true\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. <a id='toc1_'></a>[Setup](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from pprint import pprint\n",
    "from prettytable import PrettyTable\n",
    "import yfinance as yf\n",
    "import datetime as dt\n",
    "from itertools import combinations\n",
    "import pickle\n",
    "from itertools import product\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. <a id='toc2_'></a>[Model](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, num_layers, output_size):\n",
    "        super(DynamicLSTM, self).__init__()\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        self.hidden_layers.append(nn.LSTM(input_size, hidden_sizes[0], num_layers=1, batch_first=True))\n",
    "        for i in range(1, len(hidden_sizes)):\n",
    "            self.hidden_layers.append(nn.LSTM(hidden_sizes[i-1], hidden_sizes[i], num_layers=1, batch_first=True))\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.hidden_layers:\n",
    "            x, _ = layer(x.to(device))  # Move input to GPU\n",
    "        x = self.output_layer(x[:, -1, :])  # Take the output from the last time step\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. <a id='toc3_'></a>[Functions](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. <a id='toc3_1_'></a>[Prepare Data](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_data_multivariate(df, choosen_stock, startdate, enddate, features, look_back, predict_type='year'):\n",
    "    # Choose specific stock\n",
    "    data = df[df[\"Stock\"] == choosen_stock]\n",
    "\n",
    "    # Test split\n",
    "    if predict_type=='year':\n",
    "        test_data = data[data[\"Date\"].dt.year == 2023]\n",
    "    elif predict_type=='month':\n",
    "        test_data = data[(data[\"Date\"].dt.year == 2023) & (data[\"Date\"].dt.month.isin([1]))]\n",
    "    elif predict_type=='days':\n",
    "        test_data = data[data[\"Date\"].dt.year == 2023][0:20] \n",
    "    elif predict_type=='forecast':\n",
    "        test_data = data[(data[\"Date\"] >= dt.datetime(2023, 10, 12)) & (data[\"Date\"] <= enddate)]\n",
    "\n",
    "    # Train split\n",
    "    if predict_type=='forecast':\n",
    "        train_data = data[(data[\"Date\"] >= startdate) & (data[\"Date\"] <= dt.datetime(2023, 10, 11))]\n",
    "    else:\n",
    "        train_data = data[(data[\"Date\"] >= startdate) & (data[\"Date\"] <= dt.datetime(2022, 12, 31))]\n",
    "    \n",
    "    # Feature selection and engineering\n",
    "    train_data = train_data[features + [\"Date\"]].values\n",
    "    test_data = test_data[features + [\"Date\"]].values\n",
    "    \n",
    "    # Normalize the data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train_data[:, :-1] = scaler.fit_transform(train_data[:, :-1])\n",
    "    test_data[:, :-1] = scaler.transform(test_data[:, :-1])\n",
    "    \n",
    "    # Create sequences for LSTM input\n",
    "    def create_sequences(dataset, look_back):\n",
    "        X, Y, dates = [], [], []\n",
    "        for i in range(len(dataset) - look_back):\n",
    "            X.append(dataset[i:(i + look_back), :-1])\n",
    "            Y.append(dataset[i + look_back, 0])\n",
    "            dates.append(dataset[i + look_back, -1])  # Assuming the last column is 'Date'\n",
    "        return np.array(X), np.array(Y), np.array(dates)\n",
    "    train_X, train_Y, train_dates = create_sequences(train_data, look_back)\n",
    "    test_X, test_Y, test_dates = create_sequences(test_data, look_back)\n",
    "    \n",
    "    # Convert data to PyTorch tensors and move to GPU\n",
    "    train_X = torch.Tensor(train_X.astype(np.float32)).to(device)\n",
    "    train_Y = torch.Tensor(train_Y).to(device)\n",
    "    test_X = torch.Tensor(test_X.astype(np.float32)).to(device)\n",
    "    test_Y = torch.Tensor(test_Y).to(device)\n",
    "    \n",
    "    return train_X, train_Y, train_dates, test_X, test_Y, test_dates, scaler, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. <a id='toc3_2_'></a>[Train & Evaluate](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_lstm_multivariate(input_size, hidden_sizes, num_layers, output_size, learning_rate, num_epochs, train_X, train_Y, test_X, test_Y, scaler, test_data, test_dates, visualize=True):\n",
    "    # Initialize the model\n",
    "    # model = MultivariateLSTMModel(input_size, hidden_sizes, num_layers, output_size)\n",
    "    # model = DynamicLSTM(input_size, hidden_sizes, num_layers, output_size)\n",
    "    model = DynamicLSTM(input_size, hidden_sizes, num_layers, output_size).to(device)\n",
    "    # print(model)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Move data to GPU\n",
    "    train_X, train_Y, test_X, test_Y = train_X.to(device), train_Y.to(device), test_X.to(device), test_Y.to(device)\n",
    "    \n",
    "    \n",
    "    # Training the model\n",
    "    train_losses = []\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        outputs = model(train_X)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs.view(-1), train_Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "    \n",
    "    # Calculate predictions\n",
    "    model.eval()\n",
    "    train_predict = model(train_X).view(-1).cpu().detach().numpy()\n",
    "    test_predict = model(test_X).view(-1).cpu().detach().numpy()\n",
    "    \n",
    "    # Compute RMSE & MAPE\n",
    "    train_rmse = mean_squared_error(train_Y.cpu(), train_predict, squared=False)\n",
    "    test_rmse = mean_squared_error(test_Y.cpu(), test_predict, squared=False)\n",
    "    train_mape = mean_absolute_percentage_error(train_Y.cpu(), train_predict)\n",
    "    test_mape = mean_absolute_percentage_error(test_Y.cpu(), test_predict)\n",
    "    \n",
    "    # Inverse Scaling\n",
    "    # --> 1.test_predict\n",
    "    test_data1 = test_data[:, 1:-1]\n",
    "    # Ensure the second array has the same number of rows as the first array\n",
    "    test_data1 = test_data1[:test_predict.reshape(-1, 1).shape[0], :]\n",
    "    # Append the arrays\n",
    "    test_data1 = np.hstack((test_predict.reshape(-1, 1), test_data1)) \n",
    "    test_predict_inverse = scaler.inverse_transform(test_data1)[:,0]\n",
    "    \n",
    "    # --> 2.test_Y\n",
    "    test_data2 = test_data[:, :-1]\n",
    "    test_data2 = test_data2[:test_predict.reshape(-1, 1).shape[0], :]\n",
    "    test_Y_inverse = scaler.inverse_transform(test_data2)[:,0]\n",
    "    \n",
    "    # Visualize test and predictions\n",
    "    if visualize == True:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(test_dates, test_Y_inverse, label='True', linewidth=2)\n",
    "        plt.plot(test_dates, test_predict_inverse, label='Predicted', linewidth=2)\n",
    "        plt.title(\"Test vs. Predicted Prices\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Price\")\n",
    "        plt.legend()\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    \n",
    "    return model, loss, train_rmse, test_rmse, train_mape, test_mape, test_Y_inverse, test_predict_inverse "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. <a id='toc3_3_'></a>[Load Data](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(choosen_stock, predict_type):    \n",
    "    yf.pdr_override() # Override pandas datareader with yfinance\n",
    "    y_symbols = [choosen_stock]\n",
    "\n",
    "    # Train split\n",
    "    if predict_type=='forecast':\n",
    "        # State the dates\n",
    "        startdate = dt.datetime(2018, 1, 1) # start date\n",
    "        enddate = dt.datetime(2023, 12, 4) # end date\n",
    "\n",
    "        # Retrieve historical stock price data for the specified symbols and date range\n",
    "        df = yf.download(y_symbols, start=startdate, end=enddate) \n",
    "        df = df.reset_index() # Reset the index to make 'Date' a regular column\n",
    "        df['Stock'] = choosen_stock # add 'Stock' column\n",
    "        df = df[['Date', 'Stock', 'Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume']] # Reorder the columns\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        \n",
    "        # add new row\n",
    "        new_row = [{'Date':pd.to_datetime('2023-12-4T00:00:00.000000000'), 'Stock': choosen_stock , 'Adj Close': 0.0, 'Close': 0.0 , 'High': 0.0,'Low': 0.0, 'Open':0.0, 'Volume':0.0}]\n",
    "        df = pd.concat([df, pd.DataFrame(new_row)], ignore_index=True)\n",
    "        new_row = [{'Date':pd.to_datetime('2023-12-5T00:00:00.000000000'), 'Stock': choosen_stock , 'Adj Close': 0.0, 'Close': 0.0 , 'High': 0.0,'Low': 0.0, 'Open':0.0, 'Volume':0.0}]\n",
    "        df = pd.concat([df, pd.DataFrame(new_row)], ignore_index=True)\n",
    "        new_row = [{'Date':pd.to_datetime('2023-12-6T00:00:00.000000000'), 'Stock': choosen_stock , 'Adj Close': 0.0, 'Close': 0.0 , 'High': 0.0,'Low': 0.0, 'Open':0.0, 'Volume':0.0}]\n",
    "        df = pd.concat([df, pd.DataFrame(new_row)], ignore_index=True)\n",
    "        new_row = [{'Date':pd.to_datetime('2023-12-7T00:00:00.000000000'), 'Stock': choosen_stock , 'Adj Close': 0.0, 'Close': 0.0 , 'High': 0.0,'Low': 0.0, 'Open':0.0, 'Volume':0.0}]\n",
    "        df = pd.concat([df, pd.DataFrame(new_row)], ignore_index=True)\n",
    "        new_row = [{'Date':pd.to_datetime('2023-12-8T00:00:00.000000000'), 'Stock': choosen_stock , 'Adj Close': 0.0, 'Close': 0.0 , 'High': 0.0,'Low': 0.0, 'Open':0.0, 'Volume':0.0}]\n",
    "        df = pd.concat([df, pd.DataFrame(new_row)], ignore_index=True)\n",
    "        \n",
    "        return df, startdate, dt.datetime(2023, 12, 8) \n",
    "    \n",
    "    else:\n",
    "        startdate = dt.datetime(2015, 1, 1) # start date\n",
    "        enddate = dt.datetime(2023, 11, 1) # end date\n",
    "        \n",
    "        # Retrieve historical stock price data for the specified symbols and date range\n",
    "        df = yf.download(y_symbols, start=startdate, end=enddate) \n",
    "        df = df.reset_index() # Reset the index to make 'Date' a regular column\n",
    "        df['Stock'] = choosen_stock # add 'Stock' column\n",
    "        df = df[['Date', 'Stock', 'Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume']] # Reorder the columns\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "  \n",
    "        return df, startdate, enddate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. <a id='toc3_4_'></a>[Predict](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standalone prediction\n",
    "def predict(choosen_stock):\n",
    "    # Load the data\n",
    "    data, startdate, enddate = load_data(choosen_stock)\n",
    "\n",
    "    # Append the last row to the DataFrame\n",
    "    new_row = [{'Date':pd.to_datetime('2023-12-01T00:00:00.000000000'), 'Stock': choosen_stock , 'Adj Close': 0.0, 'Close': 0.0 , 'High': 0.0,'Low': 0.0, 'Open':0.0, 'Volume':0.0}]\n",
    "    data = pd.concat([data, pd.DataFrame(new_row)], ignore_index=True)\n",
    "\n",
    "    # 1. Hyperparameters\n",
    "    look_back = 5 # No. of Lags to consider\n",
    "    predict_type = 'Predict' # Predict type ['Year', 'Month', 'Days','Predict']\n",
    "    features = ['Close', 'High', 'Low', 'Open', 'Volume']\n",
    "    predict_type = 'Predict'                            # Predict type ['Year', 'Month', 'Days','Predict']\n",
    "    hidden_sizes = [64, 64]                   # Adjust the hidden_size values as needed\n",
    "    num_layers = 2                       # [1, 2, 3]\n",
    "    learning_rate = 0.001         # [0.005, 0.01, 0.02]  \n",
    "    num_epochs = 100                                    # [50, 100, 200] \n",
    "\n",
    "    # Prepare the data\n",
    "    train_X, train_Y, train_dates, test_X, test_Y, test_dates, scaler, test_data = prepare_data_multivariate(data, choosen_stock, startdate, enddate, features=features, look_back=look_back, predict_type=predict_type )\n",
    "\n",
    "    # 2. Hyperparameters\n",
    "    input_size = 5  # Number of input features (High, Low, Open, Close, Volume)\n",
    "    output_size = 1  # Number of output features (Close price)\n",
    "    num_epochs = 100\n",
    "\n",
    "    # Create the model\n",
    "    model, loss, train_rmse, test_rmse, train_mape, test_mape, test_Y_inverse, test_predict_inverse  = train_evaluate_lstm_multivariate(input_size, hidden_sizes, num_layers, output_size, learning_rate, num_epochs, train_X, train_Y, test_X, test_Y, scaler, test_data, visualize=False)\n",
    "    \n",
    "    # Formatting the prices to a desired decimal form\n",
    "    formatted_test_Y = [\"{:.4f}\".format(price) for price in test_Y_inverse.flatten()]\n",
    "    formatted_test_predict = [\"{:.4f}\".format(price) for price in test_predict_inverse.flatten()]\n",
    "    formatted_dates = [test_dates.strftime('%Y-%m-%d') for test_dates in test_dates]\n",
    "\n",
    "    return formatted_test_Y, formatted_test_predict, formatted_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. <a id='toc4_'></a>[Hyperparameter tuning](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GOOG\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "MSFT\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "META\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "AMZN\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "NFLX\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "TSLA\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "NVDA\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "GME\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Top Performing Models:\n",
      "+--------+-------+-----------+---------------+------------+-------------+------------+-------------+-----------+-----------+\n",
      "| Ticker | Model | Look Back | Learning Rate | Input Size | Hidden Size | Num Layers | Output Size | Test RMSE | Test MAPE |\n",
      "+--------+-------+-----------+---------------+------------+-------------+------------+-------------+-----------+-----------+\n",
      "|  GOOG  |   1   |     5     |      0.01     |     5      |    (128,)   |     1      |      1      |   0.2745  |   0.1979  |\n",
      "|  MSFT  |   1   |     5     |      0.01     |     5      |    (128,)   |     1      |      1      |   0.2817  |   0.3018  |\n",
      "|  META  |   1   |     5     |      0.01     |     5      |    (128,)   |     1      |      1      |   0.2316  |   0.2553  |\n",
      "|  AMZN  |   1   |     5     |      0.01     |     5      |    (128,)   |     1      |      1      |   0.2472  |   0.2027  |\n",
      "|  NFLX  |   1   |     5     |      0.01     |     5      |    (128,)   |     1      |      1      |   0.1861  |   0.2102  |\n",
      "|  TSLA  |   1   |     5     |      0.01     |     5      |    (64,)    |     1      |      1      |   0.1234  |   1.179   |\n",
      "|  NVDA  |   1   |     5     |      0.01     |     5      |    (64,)    |     1      |      1      |   0.2016  |   0.8526  |\n",
      "|  GME   |   1   |     5     |      0.01     |     5      |    (64,)    |     1      |      1      |   0.0345  |   1.0655  |\n",
      "+--------+-------+-----------+---------------+------------+-------------+------------+-------------+-----------+-----------+\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store the best models for each ticker\n",
    "all_best_models = {}\n",
    "\n",
    "for ticker in ['GOOG', 'MSFT', 'META', 'AMZN', 'NFLX', 'TSLA', 'NVDA', 'GME']:\n",
    "    print(\"\\n\" + ticker)\n",
    "    \n",
    "    # Hyperparameters\n",
    "    choosen_stock = ticker                              # ['GOOG', 'MSFT', 'META', 'AMZN', 'NFLX', 'TSLA', 'NVDA']\n",
    "    look_back_values = [5]        \n",
    "    # No. of Lags to consider [3, 5, 10, 20]\n",
    "    predict_type = 'forecast'                            # Predict type ['year', 'month', 'days','predict']\n",
    "    hidden_size_options = [64, 128]                      # Adjust the hidden_size values as needed\n",
    "    num_layers_values = [1,2]                       # [1, 2, 3]\n",
    "    learning_rate_values = [0.001, 0.01, 0.005]         # [0.005, 0.01, 0.02]  \n",
    "    num_epochs = 100                                    # [50, 100, 200] \n",
    "    top_k = 1                                           # Get the top k performing models\n",
    "\n",
    "    # ?\n",
    "    years_to_include = [2015, 2016, 2017, 2018, 2019]\n",
    "    train_days_values = [-1, 60, 100, 365, 365*2]\n",
    "\n",
    "\n",
    "    # Features\n",
    "    features = ['Close', 'High', 'Low', 'Open', 'Volume']\n",
    "    input_size = 5  # Number of input features (High, Low, Open, Close, Volume)\n",
    "    output_size = 1  # Number of output features (Close price)\n",
    "\n",
    "\n",
    "    # Load the data\n",
    "    df, startdate, enddate = load_data(choosen_stock, predict_type) \n",
    "\n",
    "    # Store best_models\n",
    "    best_models = []\n",
    "\n",
    "    # Hyperparameter tuning loop\n",
    "\n",
    "    for num_layers in num_layers_values:\n",
    "        hidden_size_values = list(product(hidden_size_options, repeat=num_layers))\n",
    "        # print(hidden_size_values)\n",
    "        for hidden_size in hidden_size_values:\n",
    "            # print(hidden_size)\n",
    "            for look_back in look_back_values:\n",
    "                for learning_rate in learning_rate_values:\n",
    "                    # print(f\"\\nHyperparameters: look_back={look_back}, hidden_size={hidden_size}, num_layers={num_layers}, learning_rate={learning_rate}\")\n",
    "                    # Prepare the data\n",
    "                    train_X, train_Y, train_dates, test_X, test_Y, test_dates, scaler, test_data = prepare_data_multivariate(df, choosen_stock, startdate, enddate, features=features, look_back=look_back, predict_type=predict_type)\n",
    "                    model, loss, train_rmse, test_rmse, train_mape, test_mape, test_Y_inverse, test_predict_inverse = train_evaluate_lstm_multivariate(input_size, hidden_size, num_layers, output_size, learning_rate, num_epochs, train_X, train_Y, test_X, test_Y, scaler, test_data, test_dates, visualize=False)\n",
    "                    best_models.append({\n",
    "                        \"model\" : model,\n",
    "                        \"look_back\" : look_back,\n",
    "                        \"learning_rate\" : learning_rate,\n",
    "                        \"input_size\" : input_size,\n",
    "                        \"hidden_size\" : hidden_size,\n",
    "                        \"num_layers\" : num_layers,\n",
    "                        \"output_size\" : output_size,\n",
    "                        \"test_rmse\": test_rmse,\n",
    "                        \"test_mape\": test_mape,\n",
    "                        \"test_X\": test_X,\n",
    "                        \"test_Y_inverse\":test_Y_inverse,\n",
    "                        \"test_predict_inverse\":test_predict_inverse,\n",
    "                        \"test_dates\":test_dates,\n",
    "                        \"test_data\" : test_data,\n",
    "                    })\n",
    "\n",
    "    # Sort the models by RMSE in ascending order\n",
    "    best_models.sort(key=lambda x: (x[\"test_rmse\"], x[\"test_mape\"]))\n",
    "\n",
    "    # Store the top-k performing models for the current ticker\n",
    "    all_best_models[ticker] = best_models[:top_k]\n",
    "\n",
    "# Save Parameters & Weights\n",
    "for ticker, models in all_best_models.items():\n",
    "    for idx, model_info in enumerate(models, start=1):\n",
    "        # Save parameters for the model reload\n",
    "        params_file_name = \"Saved Params/\" + ticker + \"_params.pkl\"\n",
    "        with open(params_file_name, 'wb') as file:\n",
    "            pickle.dump(model_info, file)\n",
    "        # print(f\"Model Parameters for {ticker} saved to {params_file_name}\")\n",
    "        \n",
    "        # Save the model weights to a pickle file\n",
    "        model_filename = f\"Saved Models/{ticker}_model\"\n",
    "        torch.save(model_info[\"model\"].state_dict(), model_filename)\n",
    "        # print(f\"Model weights for {ticker} saved to {model_filename}\")\n",
    "\n",
    "\n",
    "# Print the best models for each ticker\n",
    "# for ticker, models in all_best_models.items():\n",
    "#     print(f\"\\nTop {top_k} Performing Model for {ticker}:\")\n",
    "#     pprint(models)\n",
    "\n",
    "# Assuming all_best_models is a dictionary with tickers as keys and a list of best models as values\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Ticker\", \"Model\", \"Look Back\", \"Learning Rate\", \"Input Size\", \"Hidden Size\", \"Num Layers\", \"Output Size\", \"Test RMSE\", \"Test MAPE\"]\n",
    "\n",
    "for ticker, models in all_best_models.items():\n",
    "    for idx, model_info in enumerate(models, start=1):\n",
    "        table.add_row([\n",
    "            ticker,\n",
    "            idx,\n",
    "            model_info[\"look_back\"],\n",
    "            model_info[\"learning_rate\"],\n",
    "            model_info[\"input_size\"],\n",
    "            model_info[\"hidden_size\"],\n",
    "            model_info[\"num_layers\"],\n",
    "            model_info[\"output_size\"],\n",
    "            round(model_info[\"test_rmse\"], 4),\n",
    "            round(model_info[\"test_mape\"], 4),\n",
    "        ])\n",
    "\n",
    "# Print the combined table\n",
    "print(\"Top Performing Models:\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. <a id='toc5_'></a>[Forecast](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GOOG\n",
      "+------------+--------------+------------------+\n",
      "|    Date    | Actual Price | Predicted Price  |\n",
      "+------------+--------------+------------------+\n",
      "| 2023-11-20 |    137.92    |      136.72      |\n",
      "| 2023-11-21 |    138.62    |      136.98      |\n",
      "| 2023-11-22 |    140.02    |      137.62      |\n",
      "| 2023-11-24 |    138.22    |      138.53      |\n",
      "| 2023-11-27 |    138.05    |      138.66      |\n",
      "| 2023-11-28 |    138.62    |      138.49      |\n",
      "| 2023-11-29 |    136.4     |      138.41      |\n",
      "| 2023-11-30 |    133.92    |      138.15      |\n",
      "| 2023-12-01 |    133.32    |      136.72      |\n",
      "| ---------- | ------------ | ---------------- |\n",
      "| 2023-12-04 |     TBA      |      135.31      |\n",
      "+------------+--------------+------------------+\n",
      "\n",
      "MSFT\n",
      "+------------+--------------+------------------+\n",
      "|    Date    | Actual Price | Predicted Price  |\n",
      "+------------+--------------+------------------+\n",
      "| 2023-11-20 |    377.44    |      364.05      |\n",
      "| 2023-11-21 |    373.07    |      365.23      |\n",
      "| 2023-11-22 |    377.85    |      365.79      |\n",
      "| 2023-11-24 |    377.43    |      367.31      |\n",
      "| 2023-11-27 |    378.61    |      367.96      |\n",
      "| 2023-11-28 |    382.7     |      368.85      |\n",
      "| 2023-11-29 |    378.85    |      370.39      |\n",
      "| 2023-11-30 |    378.91    |      371.25      |\n",
      "| 2023-12-01 |    374.51    |      370.72      |\n",
      "| ---------- | ------------ | ---------------- |\n",
      "| 2023-12-04 |     TBA      |      369.34      |\n",
      "+------------+--------------+------------------+\n",
      "\n",
      "META\n",
      "+------------+--------------+------------------+\n",
      "|    Date    | Actual Price | Predicted Price  |\n",
      "+------------+--------------+------------------+\n",
      "| 2023-11-20 |    339.97    |      332.66      |\n",
      "| 2023-11-21 |    336.98    |      334.92      |\n",
      "| 2023-11-22 |    341.49    |      336.15      |\n",
      "| 2023-11-24 |    338.23    |      338.19      |\n",
      "| 2023-11-27 |    334.7     |      339.25      |\n",
      "| 2023-11-28 |    338.99    |      338.09      |\n",
      "| 2023-11-29 |    332.2     |      337.62      |\n",
      "| 2023-11-30 |    327.15    |      336.7       |\n",
      "| 2023-12-01 |    324.82    |      332.78      |\n",
      "| ---------- | ------------ | ---------------- |\n",
      "| 2023-12-04 |     TBA      |      329.31      |\n",
      "+------------+--------------+------------------+\n",
      "\n",
      "AMZN\n",
      "+------------+--------------+------------------+\n",
      "|    Date    | Actual Price | Predicted Price  |\n",
      "+------------+--------------+------------------+\n",
      "| 2023-11-20 |    146.13    |      144.82      |\n",
      "| 2023-11-21 |    143.9     |      145.78      |\n",
      "| 2023-11-22 |    146.71    |      144.98      |\n",
      "| 2023-11-24 |    146.74    |      145.93      |\n",
      "| 2023-11-27 |    147.73    |      146.99      |\n",
      "| 2023-11-28 |    147.03    |      147.89      |\n",
      "| 2023-11-29 |    146.32    |      147.97      |\n",
      "| 2023-11-30 |    146.09    |      148.41      |\n",
      "| 2023-12-01 |    147.03    |      147.64      |\n",
      "| ---------- | ------------ | ---------------- |\n",
      "| 2023-12-04 |     TBA      |      147.76      |\n",
      "+------------+--------------+------------------+\n",
      "\n",
      "NFLX\n",
      "+------------+--------------+------------------+\n",
      "|    Date    | Actual Price | Predicted Price  |\n",
      "+------------+--------------+------------------+\n",
      "| 2023-11-20 |    474.47    |      462.2       |\n",
      "| 2023-11-21 |    474.95    |      466.6       |\n",
      "| 2023-11-22 |    478.0     |      470.77      |\n",
      "| 2023-11-24 |    479.56    |      474.97      |\n",
      "| 2023-11-27 |    479.17    |      477.4       |\n",
      "| 2023-11-28 |    479.0     |      478.74      |\n",
      "| 2023-11-29 |    477.19    |      479.3       |\n",
      "| 2023-11-30 |    473.97    |      479.29      |\n",
      "| 2023-12-01 |    465.74    |      477.45      |\n",
      "| ---------- | ------------ | ---------------- |\n",
      "| 2023-12-04 |     TBA      |      474.21      |\n",
      "+------------+--------------+------------------+\n",
      "\n",
      "TSLA\n",
      "+------------+--------------+------------------+\n",
      "|    Date    | Actual Price | Predicted Price  |\n",
      "+------------+--------------+------------------+\n",
      "| 2023-11-20 |    235.6     |      236.65      |\n",
      "| 2023-11-21 |    241.2     |      237.22      |\n",
      "| 2023-11-22 |    234.21    |      238.58      |\n",
      "| 2023-11-24 |    235.45    |      238.99      |\n",
      "| 2023-11-27 |    236.08    |      238.47      |\n",
      "| 2023-11-28 |    246.72    |      237.95      |\n",
      "| 2023-11-29 |    244.14    |      239.97      |\n",
      "| 2023-11-30 |    240.08    |      244.15      |\n",
      "| 2023-12-01 |    238.83    |      244.21      |\n",
      "| ---------- | ------------ | ---------------- |\n",
      "| 2023-12-04 |     TBA      |      241.86      |\n",
      "+------------+--------------+------------------+\n",
      "\n",
      "NVDA\n",
      "+------------+--------------+------------------+\n",
      "|    Date    | Actual Price | Predicted Price  |\n",
      "+------------+--------------+------------------+\n",
      "| 2023-11-20 |    504.09    |      486.11      |\n",
      "| 2023-11-21 |    499.44    |      489.16      |\n",
      "| 2023-11-22 |    487.16    |      491.11      |\n",
      "| 2023-11-24 |    477.76    |      489.87      |\n",
      "| 2023-11-27 |    482.42    |      482.97      |\n",
      "| 2023-11-28 |    478.21    |      480.04      |\n",
      "| 2023-11-29 |    481.4     |      477.58      |\n",
      "| 2023-11-30 |    467.7     |      477.43      |\n",
      "| 2023-12-01 |    467.65    |      473.76      |\n",
      "| ---------- | ------------ | ---------------- |\n",
      "| 2023-12-04 |     TBA      |      468.91      |\n",
      "+------------+--------------+------------------+\n",
      "\n",
      "GME\n",
      "+------------+--------------+------------------+\n",
      "|    Date    | Actual Price | Predicted Price  |\n",
      "+------------+--------------+------------------+\n",
      "| 2023-11-20 |     12.8     |      12.82       |\n",
      "| 2023-11-21 |    12.55     |      12.85       |\n",
      "| 2023-11-22 |    12.29     |      12.67       |\n",
      "| 2023-11-24 |     12.2     |      12.49       |\n",
      "| 2023-11-27 |    11.91     |       12.3       |\n",
      "| 2023-11-28 |    13.49     |      12.13       |\n",
      "| 2023-11-29 |    16.25     |      12.51       |\n",
      "| 2023-11-30 |    14.55     |       15.1       |\n",
      "| 2023-12-01 |     15.3     |      15.52       |\n",
      "| ---------- | ------------ | ---------------- |\n",
      "| 2023-12-04 |     TBA      |      15.41       |\n",
      "+------------+--------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "# Forecast next day\n",
    "\n",
    "stocks = ['GOOG', 'MSFT', 'META', 'AMZN', 'NFLX', 'TSLA', 'NVDA', 'GME']\n",
    "\n",
    "for choosen_stock in stocks:\n",
    "    print(\"\\n\"+choosen_stock)\n",
    "    \n",
    "    # Function Call\n",
    "    file = open(\"Saved Params/\"+choosen_stock+\"_params.pkl\",'rb')\n",
    "    object_file = pickle.load(file)\n",
    "    model = DynamicLSTM(object_file['input_size'], object_file['hidden_size'], object_file['num_layers'], object_file['output_size']).to(device)\n",
    "    model.load_state_dict(torch.load(\"Saved Models/\"+choosen_stock+\"_model\"))\n",
    "    model.eval()\n",
    "    \n",
    "    test_predict = model(object_file['test_X']).view(-1).cpu().detach().numpy()\n",
    "    test_data = object_file['test_data']\n",
    "    test_predict_inverse = object_file['test_predict_inverse']\n",
    "    test_Y_inverse = object_file['test_Y_inverse']\n",
    "    \n",
    "    formatted_dates = [test_dates.strftime('%Y-%m-%d') for test_dates in object_file[\"test_dates\"]]\n",
    "    formatted_test_Y = [\"{:.4f}\".format(price) for price in test_Y_inverse.flatten()]\n",
    "    formatted_test_predict = [\"{:.4f}\".format(price) for price in test_predict_inverse.flatten()]\n",
    "    \n",
    "    formatted_dates = formatted_dates[-14:-4]\n",
    "    formatted_test_predict = formatted_test_predict[-14:-4]\n",
    "    \n",
    "    # Display\n",
    "    # Remove the first value and shift up the remaining values\n",
    "    actual_prices = formatted_test_Y[0:] + ['']\n",
    "    actual_prices = actual_prices[-10:]\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"Date\", \"Actual Price\", \"Predicted Price\"]\n",
    "    for date, actual_price, predicted_price in zip(formatted_dates, actual_prices, formatted_test_predict):\n",
    "        # Add a separator line before the last row\n",
    "        if date == formatted_dates[-1]:\n",
    "            table.add_row([\"-\" * 10, \"-\" * 12, \"-\" * 16])\n",
    "        table.add_row([date, round(float(actual_price), 2) if actual_price != '' else 'TBA', round(float(predicted_price), 2)])\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
