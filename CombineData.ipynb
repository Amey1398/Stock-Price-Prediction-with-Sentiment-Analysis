{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Setup](#toc1_)    \n",
    "- [Get Data](#toc2_)    \n",
    "  - [Reddit](#toc2_1_)    \n",
    "  - [Twitter](#toc2_2_)    \n",
    "  - [News](#toc2_3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Setup](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\\venv\\Scripts\\activate\n",
    "\n",
    "pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import praw\n",
    "import prawcore.exceptions\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import requests as req\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Get Data](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[Reddit](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on previous observations in Scrape_RedditPosts.ipynb, out of all methods, let us go forward with **Scraping from different Subreddits.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to scrape Reddit posts related to all stocks from different subreddits\n",
    "\n",
    "# Initialize the Reddit API client\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"2aV6_rxA1c44CoHtxY6e0A\",\n",
    "    client_secret=\"7rbu00bmyQOlnHCu-xjyTa-U5har-g\",\n",
    "    user_agent=\"Project Capstone\"\n",
    ")\n",
    "\n",
    "# list of subreddits to search\n",
    "subreddits_to_search = ['stocks', 'investing', 'wallstreetbets', 'finance', 'economy', 'stockmarket', 'business']\n",
    "\n",
    "# list of search queries\n",
    "search_queries = ['Apple Stocks OR AAPL', 'Google Stocks OR GOOG', 'Netflix Stocks OR NFLX', 'TESLA Stocks OR TSLA', 'Microsoft Stocks OR MSFT']\n",
    "\n",
    "# Define the date range (January 1, 2015, to December 31, 2020) for consistency\n",
    "start_date = datetime.date(2015, 1, 1)\n",
    "end_date = datetime.date(2020, 12, 31)\n",
    "\n",
    "# lists to store data\n",
    "titles = []\n",
    "authors = []\n",
    "scores = []\n",
    "urls = []\n",
    "contents = []\n",
    "post_dates = []\n",
    "subreddit_names = []\n",
    "query_names = []\n",
    "\n",
    "# Iterate through each subreddit\n",
    "for subreddit_name in subreddits_to_search:\n",
    "    for search_query in search_queries:\n",
    "        try:\n",
    "            subreddit = reddit.subreddit(subreddit_name)\n",
    "            posts = subreddit.search(search_query, limit=None)\n",
    "\n",
    "            # Iterate through the search results and collect data\n",
    "            for post in posts:\n",
    "                post_date = pd.to_datetime(post.created_utc, unit='s').date()\n",
    "                if start_date <= post_date <= end_date:\n",
    "                    if post.selftext:  # Check if the post has text content\n",
    "                        titles.append(post.title)\n",
    "                        authors.append(post.author)\n",
    "                        scores.append(post.score)\n",
    "                        urls.append(post.url)\n",
    "                        contents.append(post.selftext)\n",
    "                        post_dates.append(pd.to_datetime(post.created_utc, unit='s'))\n",
    "                        subreddit_names.append(subreddit_name)\n",
    "                        query_names.append(search_query[-4:])\n",
    "\n",
    "        # handle the exceptions\n",
    "        except prawcore.exceptions.NotFound as e:\n",
    "            print(f\"Error in subreddit '{subreddit_to_search}': {e}\")\n",
    "        except prawcore.exceptions.Forbidden as e:\n",
    "            print(f\"Access forbidden in subreddit '{subreddit_to_search}': {e}\")\n",
    "        except praw.exceptions.APIException as e:\n",
    "            print(f\"API Error: {e}\")\n",
    "            # Wait for a while before retrying (e.g., 5 seconds)\n",
    "            time.sleep(5)\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "data = {\n",
    "    'Query': query_names,\n",
    "    'Subreddit': subreddit_names,\n",
    "    'Title': titles,\n",
    "    'Author': authors,\n",
    "    'Score': scores,\n",
    "    'URL': urls,\n",
    "    'Content': contents,\n",
    "    'Post_Date': post_dates,\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# drop duplicate\n",
    "df = df.drop_duplicates(subset='URL')\n",
    "\n",
    "# Sort by date\n",
    "df = df.sort_values(by='Post_Date')\n",
    "\n",
    "# Store as csv file\n",
    "df.to_csv('Data\\RedditPosts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Query</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Score</th>\n",
       "      <th>URL</th>\n",
       "      <th>Content</th>\n",
       "      <th>Post_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>884</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>investing</td>\n",
       "      <td>What is the ONE stock you are most excited abo...</td>\n",
       "      <td>Iama_tomhanks</td>\n",
       "      <td>197</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/2s...</td>\n",
       "      <td>No judging, you dicks.</td>\n",
       "      <td>2015-01-11 16:42:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>654</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>investing</td>\n",
       "      <td>NFLX: Buy/Hold/Sell thoughts?</td>\n",
       "      <td>TRA8324</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/2s...</td>\n",
       "      <td>domestic growth is definitely slowing, but can...</td>\n",
       "      <td>2015-01-12 20:48:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1290</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>finance</td>\n",
       "      <td>Anyone have the marketing/press documents ISIS...</td>\n",
       "      <td>Warhawk_1</td>\n",
       "      <td>7</td>\n",
       "      <td>https://www.reddit.com/r/finance/comments/2sgr...</td>\n",
       "      <td>Was a doc 80-120 pages long, think it was for ...</td>\n",
       "      <td>2015-01-15 01:02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>378</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>investing</td>\n",
       "      <td>http://www.gurufocus.com/stock/AAPL</td>\n",
       "      <td>Novast</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/2s...</td>\n",
       "      <td>I am new to investing in stocks and so far hav...</td>\n",
       "      <td>2015-01-15 15:24:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1306</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>finance</td>\n",
       "      <td>Tesla will not be profitable, under generally ...</td>\n",
       "      <td>chocolateolive</td>\n",
       "      <td>85</td>\n",
       "      <td>https://www.reddit.com/r/finance/comments/2sm1...</td>\n",
       "      <td>in the WSJ, Musk said he \"doesn't expect Tesla...</td>\n",
       "      <td>2015-01-16 08:37:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>202</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>stocks</td>\n",
       "      <td>Tesla Will Hit 500,000 Deliveries for 2020, An...</td>\n",
       "      <td>coolcomfort123</td>\n",
       "      <td>1620</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/kn48j...</td>\n",
       "      <td>https://www.thestreet.com/investing/tesla-tsla...</td>\n",
       "      <td>2020-12-30 15:29:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>1329</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>economy</td>\n",
       "      <td>What do you think, could tesla stock collapse ...</td>\n",
       "      <td>jumplineg</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/economy/comments/knlf...</td>\n",
       "      <td>&amp;#x200B;\\n\\nhttps://preview.redd.it/zuju24i54h...</td>\n",
       "      <td>2020-12-31 07:20:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>206</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>stocks</td>\n",
       "      <td>Tesla Short Sellers Lost $38 Billion in 2020 a...</td>\n",
       "      <td>coolcomfort123</td>\n",
       "      <td>2498</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/knqco...</td>\n",
       "      <td>https://www.bloombergquint.com/business/tesla-...</td>\n",
       "      <td>2020-12-31 13:52:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>958</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>AAPL is the 2021 Play</td>\n",
       "      <td>thinkclay</td>\n",
       "      <td>87</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>Missed out on the TSLA run in 2020? Aww, that’...</td>\n",
       "      <td>2020-12-31 17:11:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>687</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>investing</td>\n",
       "      <td>Why the $TSLA bubble will not burst?</td>\n",
       "      <td>BenDoverR8Now</td>\n",
       "      <td>20</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/kn...</td>\n",
       "      <td>A correction (\\~-20%) can happen, but the bubb...</td>\n",
       "      <td>2020-12-31 22:12:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1579 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 Query       Subreddit  \\\n",
       "0            884  MSFT       investing   \n",
       "1            654  NFLX       investing   \n",
       "2           1290  GOOG         finance   \n",
       "3            378  AAPL       investing   \n",
       "4           1306  TSLA         finance   \n",
       "...          ...   ...             ...   \n",
       "1574         202  TSLA          stocks   \n",
       "1575        1329  GOOG         economy   \n",
       "1576         206  TSLA          stocks   \n",
       "1577         958  AAPL  wallstreetbets   \n",
       "1578         687  TSLA       investing   \n",
       "\n",
       "                                                  Title          Author  \\\n",
       "0     What is the ONE stock you are most excited abo...   Iama_tomhanks   \n",
       "1                         NFLX: Buy/Hold/Sell thoughts?         TRA8324   \n",
       "2     Anyone have the marketing/press documents ISIS...       Warhawk_1   \n",
       "3                   http://www.gurufocus.com/stock/AAPL          Novast   \n",
       "4     Tesla will not be profitable, under generally ...  chocolateolive   \n",
       "...                                                 ...             ...   \n",
       "1574  Tesla Will Hit 500,000 Deliveries for 2020, An...  coolcomfort123   \n",
       "1575  What do you think, could tesla stock collapse ...       jumplineg   \n",
       "1576  Tesla Short Sellers Lost $38 Billion in 2020 a...  coolcomfort123   \n",
       "1577                              AAPL is the 2021 Play       thinkclay   \n",
       "1578               Why the $TSLA bubble will not burst?   BenDoverR8Now   \n",
       "\n",
       "      Score                                                URL  \\\n",
       "0       197  https://www.reddit.com/r/investing/comments/2s...   \n",
       "1         0  https://www.reddit.com/r/investing/comments/2s...   \n",
       "2         7  https://www.reddit.com/r/finance/comments/2sgr...   \n",
       "3         0  https://www.reddit.com/r/investing/comments/2s...   \n",
       "4        85  https://www.reddit.com/r/finance/comments/2sm1...   \n",
       "...     ...                                                ...   \n",
       "1574   1620  https://www.reddit.com/r/stocks/comments/kn48j...   \n",
       "1575      0  https://www.reddit.com/r/economy/comments/knlf...   \n",
       "1576   2498  https://www.reddit.com/r/stocks/comments/knqco...   \n",
       "1577     87  https://www.reddit.com/r/wallstreetbets/commen...   \n",
       "1578     20  https://www.reddit.com/r/investing/comments/kn...   \n",
       "\n",
       "                                                Content            Post_Date  \n",
       "0                                No judging, you dicks.  2015-01-11 16:42:11  \n",
       "1     domestic growth is definitely slowing, but can...  2015-01-12 20:48:03  \n",
       "2     Was a doc 80-120 pages long, think it was for ...  2015-01-15 01:02:27  \n",
       "3     I am new to investing in stocks and so far hav...  2015-01-15 15:24:00  \n",
       "4     in the WSJ, Musk said he \"doesn't expect Tesla...  2015-01-16 08:37:12  \n",
       "...                                                 ...                  ...  \n",
       "1574  https://www.thestreet.com/investing/tesla-tsla...  2020-12-30 15:29:29  \n",
       "1575  &#x200B;\\n\\nhttps://preview.redd.it/zuju24i54h...  2020-12-31 07:20:47  \n",
       "1576  https://www.bloombergquint.com/business/tesla-...  2020-12-31 13:52:20  \n",
       "1577  Missed out on the TSLA run in 2020? Aww, that’...  2020-12-31 17:11:40  \n",
       "1578  A correction (\\~-20%) can happen, but the bubb...  2020-12-31 22:12:10  \n",
       "\n",
       "[1579 rows x 9 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reddit = pd.read_csv('Data/RedditPosts.csv')\n",
    "df_reddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can drop 'Unnamed: 0' column as it holds no information.\n",
    "\n",
    "Check for statistics for 'Score' column.\n",
    "\n",
    "'Post_Date' will be important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1579 entries, 0 to 1578\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  1579 non-null   int64 \n",
      " 1   Query       1579 non-null   object\n",
      " 2   Subreddit   1579 non-null   object\n",
      " 3   Title       1579 non-null   object\n",
      " 4   Author      1579 non-null   object\n",
      " 5   Score       1579 non-null   int64 \n",
      " 6   URL         1579 non-null   object\n",
      " 7   Content     1579 non-null   object\n",
      " 8   Post_Date   1579 non-null   object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 111.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_reddit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the specific column\n",
    "df_reddit.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1579.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>330.006966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>781.404373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>284.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10166.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Score\n",
       "count   1579.000000\n",
       "mean     330.006966\n",
       "std      781.404373\n",
       "min        0.000000\n",
       "25%        6.000000\n",
       "50%       47.000000\n",
       "75%      284.500000\n",
       "max    10166.000000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reddit.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the qauntiles, Q1 is 6, Q2 is 47 and Q3 is 284.\n",
    "\n",
    "Q3 scores would surely be useful, however we can think of dropping scores below Q1 as they might not be useful and might introduce noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Query\n",
       "NFLX    418\n",
       "MSFT    323\n",
       "AAPL    321\n",
       "TSLA    287\n",
       "GOOG    230\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts of Posts per stock\n",
    "df_reddit['Query'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have around 300 posts for each of the companies across 6 years 2015-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Post_Date\n",
       "2015    45\n",
       "2016    26\n",
       "2017    19\n",
       "2018    34\n",
       "2019    26\n",
       "2020    80\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group the data by year and count the number of posts in each year for specified stocks\n",
    "pd.to_datetime(df_reddit[df_reddit['Query']=='GOOG']['Post_Date']).dt.year.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~20 posts per year for a stock.\n",
    "\n",
    "More no. of posts after year 2020 for a stock: On average, there are >100 posts after year 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[Twitter](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>writer</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>550441509175443456</td>\n",
       "      <td>VisualStockRSRC</td>\n",
       "      <td>2015-01-01 00:00:57</td>\n",
       "      <td>lx21 made $10,008  on $AAPL -Check it out! htt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:00:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>550441672312512512</td>\n",
       "      <td>KeralaGuy77</td>\n",
       "      <td>2015-01-01 00:01:36</td>\n",
       "      <td>Insanity of today weirdo massive selling. $aap...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>550441732014223360</td>\n",
       "      <td>DozenStocks</td>\n",
       "      <td>2015-01-01 00:01:50</td>\n",
       "      <td>S&amp;P100 #Stocks Performance $HD $LOW $SBUX $TGT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:01:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>550442977802207232</td>\n",
       "      <td>ShowDreamCar</td>\n",
       "      <td>2015-01-01 00:06:47</td>\n",
       "      <td>$GM $TSLA: Volkswagen Pushes 2014 Record Recal...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:06:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>550443807834402816</td>\n",
       "      <td>i_Know_First</td>\n",
       "      <td>2015-01-01 00:10:05</td>\n",
       "      <td>Swing Trading: Up To 8.91% Return In 14 Days h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:10:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336440</th>\n",
       "      <td>1212159838882533376</td>\n",
       "      <td>ShortingIsFun</td>\n",
       "      <td>2019-12-31 23:53:21</td>\n",
       "      <td>In 2020 I may start Tweeting out positive news...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>23:53:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336441</th>\n",
       "      <td>1212160015332728833</td>\n",
       "      <td>Commuternyc</td>\n",
       "      <td>2019-12-31 23:54:03</td>\n",
       "      <td>Patiently Waiting for the no twitter sitter tw...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>23:54:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336442</th>\n",
       "      <td>1212160410692046849</td>\n",
       "      <td>MoriaCrypto</td>\n",
       "      <td>2019-12-31 23:55:37</td>\n",
       "      <td>I don't discriminate. I own both $aapl and $ms...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>23:55:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336443</th>\n",
       "      <td>1212160410692046849</td>\n",
       "      <td>MoriaCrypto</td>\n",
       "      <td>2019-12-31 23:55:37</td>\n",
       "      <td>I don't discriminate. I own both $aapl and $ms...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>23:55:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336444</th>\n",
       "      <td>1212160477159206912</td>\n",
       "      <td>treabase</td>\n",
       "      <td>2019-12-31 23:55:53</td>\n",
       "      <td>$AAPL #patent 10,522,475 Vertical interconnect...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>23:55:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4336445 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tweet_id           writer           post_date  \\\n",
       "0         550441509175443456  VisualStockRSRC 2015-01-01 00:00:57   \n",
       "1         550441672312512512      KeralaGuy77 2015-01-01 00:01:36   \n",
       "2         550441732014223360      DozenStocks 2015-01-01 00:01:50   \n",
       "3         550442977802207232     ShowDreamCar 2015-01-01 00:06:47   \n",
       "4         550443807834402816     i_Know_First 2015-01-01 00:10:05   \n",
       "...                      ...              ...                 ...   \n",
       "4336440  1212159838882533376    ShortingIsFun 2019-12-31 23:53:21   \n",
       "4336441  1212160015332728833      Commuternyc 2019-12-31 23:54:03   \n",
       "4336442  1212160410692046849      MoriaCrypto 2019-12-31 23:55:37   \n",
       "4336443  1212160410692046849      MoriaCrypto 2019-12-31 23:55:37   \n",
       "4336444  1212160477159206912         treabase 2019-12-31 23:55:53   \n",
       "\n",
       "                                                      body  comment_num  \\\n",
       "0        lx21 made $10,008  on $AAPL -Check it out! htt...            0   \n",
       "1        Insanity of today weirdo massive selling. $aap...            0   \n",
       "2        S&P100 #Stocks Performance $HD $LOW $SBUX $TGT...            0   \n",
       "3        $GM $TSLA: Volkswagen Pushes 2014 Record Recal...            0   \n",
       "4        Swing Trading: Up To 8.91% Return In 14 Days h...            0   \n",
       "...                                                    ...          ...   \n",
       "4336440  In 2020 I may start Tweeting out positive news...            0   \n",
       "4336441  Patiently Waiting for the no twitter sitter tw...            0   \n",
       "4336442  I don't discriminate. I own both $aapl and $ms...            1   \n",
       "4336443  I don't discriminate. I own both $aapl and $ms...            1   \n",
       "4336444  $AAPL #patent 10,522,475 Vertical interconnect...            0   \n",
       "\n",
       "         retweet_num  like_num ticker_symbol        date      time  \n",
       "0                  0         1          AAPL  2015-01-01  00:00:57  \n",
       "1                  0         0          AAPL  2015-01-01  00:01:36  \n",
       "2                  0         0          AMZN  2015-01-01  00:01:50  \n",
       "3                  0         1          TSLA  2015-01-01  00:06:47  \n",
       "4                  0         1          AAPL  2015-01-01  00:10:05  \n",
       "...              ...       ...           ...         ...       ...  \n",
       "4336440            0         1          TSLA  2019-12-31  23:53:21  \n",
       "4336441            0         5          TSLA  2019-12-31  23:54:03  \n",
       "4336442            0         1          AAPL  2019-12-31  23:55:37  \n",
       "4336443            0         1          MSFT  2019-12-31  23:55:37  \n",
       "4336444            0         0          AAPL  2019-12-31  23:55:53  \n",
       "\n",
       "[4336445 rows x 10 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "tweet_df = pd.read_csv(\"Data/Tweet.csv\")\n",
    "company_tweet_df = pd.read_csv(\"Data/Company_Tweet.csv\")\n",
    "\n",
    "# Merge dataset by tweet_id to get which tweet corresponds to which ticker\n",
    "tweet_company_merge = pd.merge(tweet_df,company_tweet_df,on='tweet_id',how='inner')\n",
    "\n",
    "# Changing Google's 2 tickers to - GOOGL\n",
    "tweet_company_merge.loc[tweet_company_merge['ticker_symbol'] == 'GOOGL', 'ticker_symbol'] = 'GOOG'\n",
    "\n",
    "# Date to correct format\n",
    "tweet_company_merge['post_date'] = pd.to_datetime(tweet_company_merge['post_date'], unit='s')\n",
    "\n",
    "# Separate date and time\n",
    "tweet_company_merge['date'] = tweet_company_merge['post_date'].dt.date\n",
    "tweet_company_merge['time'] = tweet_company_merge['post_date'].dt.time\n",
    "\n",
    "df_twitter = tweet_company_merge\n",
    "df_twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4M tweets in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4336445 entries, 0 to 4336444\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Dtype         \n",
      "---  ------         -----         \n",
      " 0   tweet_id       int64         \n",
      " 1   writer         object        \n",
      " 2   post_date      datetime64[ns]\n",
      " 3   body           object        \n",
      " 4   comment_num    int64         \n",
      " 5   retweet_num    int64         \n",
      " 6   like_num       int64         \n",
      " 7   ticker_symbol  object        \n",
      " 8   date           object        \n",
      " 9   time           object        \n",
      "dtypes: datetime64[ns](1), int64(4), object(5)\n",
      "memory usage: 330.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_twitter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id             0\n",
       "writer           55919\n",
       "post_date            0\n",
       "body                 0\n",
       "comment_num          0\n",
       "retweet_num          0\n",
       "like_num             0\n",
       "ticker_symbol        0\n",
       "date                 0\n",
       "time                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twitter.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"writer\" contains 55k missing values out of 4M tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticker_symbol\n",
       "AAPL    1425013\n",
       "TSLA    1096868\n",
       "GOOG     720138\n",
       "AMZN     718715\n",
       "MSFT     375711\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts of tweets per stock\n",
    "df_twitter['ticker_symbol'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~80k tweets for each stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2015    195796\n",
       "2016    186084\n",
       "2017    120382\n",
       "2018    117158\n",
       "2019    100718\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group the data by year and count the number of posts in each year for specified stocks\n",
    "pd.to_datetime(df_twitter[df_twitter['ticker_symbol']=='GOOG']['date']).dt.year.value_counts().sort_index()\n",
    "\n",
    "\n",
    "# Group the data by year and count the number of posts in each year for specified stocks\n",
    "# pd.to_datetime(df_reddit[df_reddit['Query']=='GOOG']['Post_Date']).dt.year.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~14k tweets per year for a stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>post_date</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.336445e+06</td>\n",
       "      <td>4336445</td>\n",
       "      <td>4.336445e+06</td>\n",
       "      <td>4.336445e+06</td>\n",
       "      <td>4.336445e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.834282e+17</td>\n",
       "      <td>2017-07-07 20:51:06.490715136</td>\n",
       "      <td>2.923863e-01</td>\n",
       "      <td>6.347647e-01</td>\n",
       "      <td>2.103625e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.504415e+17</td>\n",
       "      <td>2015-01-01 00:00:57</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.185450e+17</td>\n",
       "      <td>2016-04-08 21:04:16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.825934e+17</td>\n",
       "      <td>2017-07-05 13:33:54</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.054776e+18</td>\n",
       "      <td>2018-10-23 16:44:39</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.212160e+18</td>\n",
       "      <td>2019-12-31 23:55:53</td>\n",
       "      <td>6.310000e+02</td>\n",
       "      <td>9.990000e+02</td>\n",
       "      <td>9.990000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.927735e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.885788e+00</td>\n",
       "      <td>6.986371e+00</td>\n",
       "      <td>1.371744e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tweet_id                      post_date   comment_num  \\\n",
       "count  4.336445e+06                        4336445  4.336445e+06   \n",
       "mean   8.834282e+17  2017-07-07 20:51:06.490715136  2.923863e-01   \n",
       "min    5.504415e+17            2015-01-01 00:00:57  0.000000e+00   \n",
       "25%    7.185450e+17            2016-04-08 21:04:16  0.000000e+00   \n",
       "50%    8.825934e+17            2017-07-05 13:33:54  0.000000e+00   \n",
       "75%    1.054776e+18            2018-10-23 16:44:39  0.000000e+00   \n",
       "max    1.212160e+18            2019-12-31 23:55:53  6.310000e+02   \n",
       "std    1.927735e+17                            NaN  1.885788e+00   \n",
       "\n",
       "        retweet_num      like_num  \n",
       "count  4.336445e+06  4.336445e+06  \n",
       "mean   6.347647e-01  2.103625e+00  \n",
       "min    0.000000e+00  0.000000e+00  \n",
       "25%    0.000000e+00  0.000000e+00  \n",
       "50%    0.000000e+00  0.000000e+00  \n",
       "75%    0.000000e+00  1.000000e+00  \n",
       "max    9.990000e+02  9.990000e+02  \n",
       "std    6.986371e+00  1.371744e+01  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twitter.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Q3 for number of comments, retweets, likes is < 1. This means that most of the tweets have not been engaged into activities by the users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_3_'></a>[News](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sohmt\\AppData\\Local\\Temp\\ipykernel_7844\\2718190284.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['year'] = pd.DatetimeIndex(filtered_df['date']).year\n",
      "C:\\Users\\sohmt\\AppData\\Local\\Temp\\ipykernel_7844\\2718190284.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['year'] = pd.DatetimeIndex(filtered_df['date']).year\n",
      "C:\\Users\\sohmt\\AppData\\Local\\Temp\\ipykernel_7844\\2718190284.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['year'] = pd.DatetimeIndex(filtered_df['date']).year\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "df_analyst_ratings_processed = pd.read_csv(\"Data/analyst_ratings_processed.csv\", encoding='UTF-8')\n",
    "df_analyst_ratings_processed['stock'] = df_analyst_ratings_processed['stock'].replace(['GOOG', 'GOOGL'], 'GOOG')\n",
    "df_raw_analyst_ratings = pd.read_csv(\"Data/raw_analyst_ratings.csv\", encoding = 'UTF-8')\n",
    "df_partner_headlines= pd.read_csv(\"Data/raw_partner_headlines.csv\", encoding = 'UTF-8')\n",
    "\n",
    "\n",
    "# filter the dataframe to contain values between years 2015-2020\n",
    "def filter_dataframe (df):\n",
    "  startdate = pd.to_datetime(\"2015-01-01\").date()\n",
    "  enddate = pd.to_datetime(\"2020-12-31\").date()\n",
    "  df['date'] = pd.to_datetime(df['date'], errors='coerce', utc=True)\n",
    "  df['date'] = df['date'].dt.date\n",
    "  df = df.loc[(df['date'] >= startdate) & (df['date'] <= enddate)]\n",
    "  return df\n",
    "\n",
    "df_analyst_ratings_processed = filter_dataframe(df_analyst_ratings_processed)\n",
    "df_raw_analyst_ratings = filter_dataframe(df_raw_analyst_ratings)\n",
    "df_partner_headlines = filter_dataframe(df_partner_headlines)\n",
    "\n",
    "\n",
    "# filter the dataframe to contain only specific stocks\n",
    "def get_statistics(df):\n",
    "  categories_to_check = ['AAPL', 'GOOG','GOOGL', 'AMZN', 'MSFT','TSLA']\n",
    "  filtered_df = df[df['stock'].isin(categories_to_check)]\n",
    "  filtered_df['year'] = pd.DatetimeIndex(filtered_df['date']).year\n",
    "  return filtered_df\n",
    "\n",
    "df_analyst_ratings_processed = get_statistics(df_analyst_ratings_processed)\n",
    "df_raw_analyst_ratings = get_statistics(df_raw_analyst_ratings)\n",
    "df_partner_headlines = get_statistics(df_partner_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3668</th>\n",
       "      <td>7120.0</td>\n",
       "      <td>Tech Stocks And FAANGS Strong Again To Start D...</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3669</th>\n",
       "      <td>7121.0</td>\n",
       "      <td>10 Biggest Price Target Changes For Wednesday</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3670</th>\n",
       "      <td>7122.0</td>\n",
       "      <td>Benzinga Pro's Top 5 Stocks To Watch For Wed.,...</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3671</th>\n",
       "      <td>7123.0</td>\n",
       "      <td>Deutsche Bank Maintains Buy on Apple, Raises P...</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3672</th>\n",
       "      <td>7124.0</td>\n",
       "      <td>Apple To Let Users Trade In Their Mac Computer...</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250207</th>\n",
       "      <td>1263065.0</td>\n",
       "      <td>Electrek.Co Tweet: Tesla's head of Europe is out</td>\n",
       "      <td>2019-07-02</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250208</th>\n",
       "      <td>1263066.0</td>\n",
       "      <td>Tesla's Q2 Delivery Number Could Cause A Big Move</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250209</th>\n",
       "      <td>1263067.0</td>\n",
       "      <td>'Tesla Electric Airplane? Elon Musk sees elect...</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250210</th>\n",
       "      <td>1263068.0</td>\n",
       "      <td>UPDATE: JMP Reiterates Outperform, $347 Target...</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250211</th>\n",
       "      <td>1263069.0</td>\n",
       "      <td>Tesla shares are trading higher after JMP Secu...</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5523 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0                                              title  \\\n",
       "3668         7120.0  Tech Stocks And FAANGS Strong Again To Start D...   \n",
       "3669         7121.0      10 Biggest Price Target Changes For Wednesday   \n",
       "3670         7122.0  Benzinga Pro's Top 5 Stocks To Watch For Wed.,...   \n",
       "3671         7123.0  Deutsche Bank Maintains Buy on Apple, Raises P...   \n",
       "3672         7124.0  Apple To Let Users Trade In Their Mac Computer...   \n",
       "...             ...                                                ...   \n",
       "1250207   1263065.0   Electrek.Co Tweet: Tesla's head of Europe is out   \n",
       "1250208   1263066.0  Tesla's Q2 Delivery Number Could Cause A Big Move   \n",
       "1250209   1263067.0  'Tesla Electric Airplane? Elon Musk sees elect...   \n",
       "1250210   1263068.0  UPDATE: JMP Reiterates Outperform, $347 Target...   \n",
       "1250211   1263069.0  Tesla shares are trading higher after JMP Secu...   \n",
       "\n",
       "               date stock  year  \n",
       "3668     2020-06-10  AAPL  2020  \n",
       "3669     2020-06-10  AAPL  2020  \n",
       "3670     2020-06-10  AAPL  2020  \n",
       "3671     2020-06-10  AAPL  2020  \n",
       "3672     2020-06-10  AAPL  2020  \n",
       "...             ...   ...   ...  \n",
       "1250207  2019-07-02  TSLA  2019  \n",
       "1250208  2019-07-01  TSLA  2019  \n",
       "1250209  2019-07-01  TSLA  2019  \n",
       "1250210  2019-07-01  TSLA  2019  \n",
       "1250211  2019-07-01  TSLA  2019  \n",
       "\n",
       "[5523 rows x 5 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analyst_ratings_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6680</th>\n",
       "      <td>7120</td>\n",
       "      <td>Tech Stocks And FAANGS Strong Again To Start D...</td>\n",
       "      <td>https://www.benzinga.com/government/20/06/1622...</td>\n",
       "      <td>JJ Kinahan</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6681</th>\n",
       "      <td>7121</td>\n",
       "      <td>10 Biggest Price Target Changes For Wednesday</td>\n",
       "      <td>https://www.benzinga.com/analyst-ratings/price...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6682</th>\n",
       "      <td>7122</td>\n",
       "      <td>Benzinga Pro's Top 5 Stocks To Watch For Wed.,...</td>\n",
       "      <td>https://www.benzinga.com/short-sellers/20/06/1...</td>\n",
       "      <td>Benzinga Newsdesk</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6683</th>\n",
       "      <td>7123</td>\n",
       "      <td>Deutsche Bank Maintains Buy on Apple, Raises P...</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16219873/d...</td>\n",
       "      <td>Benzinga Newsdesk</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6684</th>\n",
       "      <td>7124</td>\n",
       "      <td>Apple To Let Users Trade In Their Mac Computer...</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16218697/a...</td>\n",
       "      <td>Neer Varshney</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                           headline  \\\n",
       "6680        7120  Tech Stocks And FAANGS Strong Again To Start D...   \n",
       "6681        7121      10 Biggest Price Target Changes For Wednesday   \n",
       "6682        7122  Benzinga Pro's Top 5 Stocks To Watch For Wed.,...   \n",
       "6683        7123  Deutsche Bank Maintains Buy on Apple, Raises P...   \n",
       "6684        7124  Apple To Let Users Trade In Their Mac Computer...   \n",
       "\n",
       "                                                    url          publisher  \\\n",
       "6680  https://www.benzinga.com/government/20/06/1622...         JJ Kinahan   \n",
       "6681  https://www.benzinga.com/analyst-ratings/price...         Lisa Levin   \n",
       "6682  https://www.benzinga.com/short-sellers/20/06/1...  Benzinga Newsdesk   \n",
       "6683  https://www.benzinga.com/news/20/06/16219873/d...  Benzinga Newsdesk   \n",
       "6684  https://www.benzinga.com/news/20/06/16218697/a...      Neer Varshney   \n",
       "\n",
       "            date stock  year  \n",
       "6680  2020-06-10  AAPL  2020  \n",
       "6681  2020-06-10  AAPL  2020  \n",
       "6682  2020-06-10  AAPL  2020  \n",
       "6683  2020-06-10  AAPL  2020  \n",
       "6684  2020-06-10  AAPL  2020  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_analyst_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4067</th>\n",
       "      <td>4130</td>\n",
       "      <td>American Pie</td>\n",
       "      <td>https://talkmarkets.com/content/american-pie?p...</td>\n",
       "      <td>TalkMarkets</td>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4068</th>\n",
       "      <td>4131</td>\n",
       "      <td>Tech Giants Dare Antitrust Deal Watchdogs</td>\n",
       "      <td>https://talkmarkets.com/content/tech-giants-da...</td>\n",
       "      <td>TalkMarkets</td>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>4132</td>\n",
       "      <td>MoneyGram Shares Jump 50% As Western Union Rep...</td>\n",
       "      <td>https://talkmarkets.com/content/moneygram-shar...</td>\n",
       "      <td>TalkMarkets</td>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4070</th>\n",
       "      <td>4133</td>\n",
       "      <td>All Eyes on Market Volatility</td>\n",
       "      <td>https://talkmarkets.com/content/all-eyes-on-ma...</td>\n",
       "      <td>TalkMarkets</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4071</th>\n",
       "      <td>4134</td>\n",
       "      <td>Warren Buffett's Berkshire Hathaway Turns Up S...</td>\n",
       "      <td>http://www.gurufocus.com/news/1152965/warren-b...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715202</th>\n",
       "      <td>716897</td>\n",
       "      <td>Fundamentun, LLC Buys WisdomTree U.S. Dividend...</td>\n",
       "      <td>http://www.gurufocus.com/news/1125032/fundamen...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-04</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715203</th>\n",
       "      <td>716898</td>\n",
       "      <td>The Zacks Analyst Blog Highlights: Microsoft, ...</td>\n",
       "      <td>http://www.zacks.com/stock/news/912835/the-zac...</td>\n",
       "      <td>Zacks</td>\n",
       "      <td>2020-05-04</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715204</th>\n",
       "      <td>716899</td>\n",
       "      <td>Zacks Investment Ideas feature highlights: Goo...</td>\n",
       "      <td>http://www.zacks.com/stock/news/912746/zacks-i...</td>\n",
       "      <td>Zacks</td>\n",
       "      <td>2020-05-04</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715205</th>\n",
       "      <td>716900</td>\n",
       "      <td>BT Investment Management Ltd Buys Atmos Energy...</td>\n",
       "      <td>http://www.gurufocus.com/news/1124838/bt-inves...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-04</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715206</th>\n",
       "      <td>716901</td>\n",
       "      <td>Tech Companies Gun for Zoom; Video Conferencin...</td>\n",
       "      <td>https://talkmarkets.com/content/tech-companies...</td>\n",
       "      <td>TalkMarkets</td>\n",
       "      <td>2020-05-02</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                           headline  \\\n",
       "4067          4130                                       American Pie   \n",
       "4068          4131          Tech Giants Dare Antitrust Deal Watchdogs   \n",
       "4069          4132  MoneyGram Shares Jump 50% As Western Union Rep...   \n",
       "4070          4133                      All Eyes on Market Volatility   \n",
       "4071          4134  Warren Buffett's Berkshire Hathaway Turns Up S...   \n",
       "...            ...                                                ...   \n",
       "715202      716897  Fundamentun, LLC Buys WisdomTree U.S. Dividend...   \n",
       "715203      716898  The Zacks Analyst Blog Highlights: Microsoft, ...   \n",
       "715204      716899  Zacks Investment Ideas feature highlights: Goo...   \n",
       "715205      716900  BT Investment Management Ltd Buys Atmos Energy...   \n",
       "715206      716901  Tech Companies Gun for Zoom; Video Conferencin...   \n",
       "\n",
       "                                                      url    publisher  \\\n",
       "4067    https://talkmarkets.com/content/american-pie?p...  TalkMarkets   \n",
       "4068    https://talkmarkets.com/content/tech-giants-da...  TalkMarkets   \n",
       "4069    https://talkmarkets.com/content/moneygram-shar...  TalkMarkets   \n",
       "4070    https://talkmarkets.com/content/all-eyes-on-ma...  TalkMarkets   \n",
       "4071    http://www.gurufocus.com/news/1152965/warren-b...    GuruFocus   \n",
       "...                                                   ...          ...   \n",
       "715202  http://www.gurufocus.com/news/1125032/fundamen...    GuruFocus   \n",
       "715203  http://www.zacks.com/stock/news/912835/the-zac...        Zacks   \n",
       "715204  http://www.zacks.com/stock/news/912746/zacks-i...        Zacks   \n",
       "715205  http://www.gurufocus.com/news/1124838/bt-inves...    GuruFocus   \n",
       "715206  https://talkmarkets.com/content/tech-companies...  TalkMarkets   \n",
       "\n",
       "              date  stock  year  \n",
       "4067    2020-06-02   AAPL  2020  \n",
       "4068    2020-06-02   AAPL  2020  \n",
       "4069    2020-06-02   AAPL  2020  \n",
       "4070    2020-06-01   AAPL  2020  \n",
       "4071    2020-06-01   AAPL  2020  \n",
       "...            ...    ...   ...  \n",
       "715202  2020-05-04  GOOGL  2020  \n",
       "715203  2020-05-04  GOOGL  2020  \n",
       "715204  2020-05-04  GOOGL  2020  \n",
       "715205  2020-05-04  GOOGL  2020  \n",
       "715206  2020-05-02  GOOGL  2020  \n",
       "\n",
       "[212 rows x 7 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_partner_headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of rows in the df_analytics: 5523\n",
    "\n",
    "Number of rows in the df_analyst_rating: 50\n",
    "\n",
    "Number of rows in the df_partner_headlines: 212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news = df_analyst_ratings_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the specific column\n",
    "df_news.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5523 entries, 3668 to 1250211\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   title   5523 non-null   object\n",
      " 1   date    5523 non-null   object\n",
      " 2   stock   5523 non-null   object\n",
      " 3   year    5523 non-null   int32 \n",
      "dtypes: int32(1), object(3)\n",
      "memory usage: 194.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_news.info()\n",
    "df_news['date'] = pd.to_datetime(df_news['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5523</td>\n",
       "      <td>5523.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2019-11-24 20:43:24.671374336</td>\n",
       "      <td>2019.475647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2018-07-25 00:00:00</td>\n",
       "      <td>2018.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2019-08-08 00:00:00</td>\n",
       "      <td>2019.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2020-01-21 00:00:00</td>\n",
       "      <td>2020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2020-04-13 00:00:00</td>\n",
       "      <td>2020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2020-06-10 00:00:00</td>\n",
       "      <td>2020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                date         year\n",
       "count                           5523  5523.000000\n",
       "mean   2019-11-24 20:43:24.671374336  2019.475647\n",
       "min              2018-07-25 00:00:00  2018.000000\n",
       "25%              2019-08-08 00:00:00  2019.000000\n",
       "50%              2020-01-21 00:00:00  2020.000000\n",
       "75%              2020-04-13 00:00:00  2020.000000\n",
       "max              2020-06-10 00:00:00  2020.000000\n",
       "std                              NaN     0.611296"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stock\n",
       "GOOG    2794\n",
       "TSLA    1930\n",
       "AAPL     469\n",
       "AMZN     330\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news['stock'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~400 posts for AAPL and AMZN with ~2000 posts for GOOG, TSLA.\n",
    "\n",
    "This is because the start date is July2018 and the end date is June2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "2018     343\n",
      "2019    1477\n",
      "2020     974\n",
      "Name: count, dtype: int64\n",
      "date\n",
      "2019     733\n",
      "2020    1197\n",
      "Name: count, dtype: int64\n",
      "date\n",
      "2020    469\n",
      "Name: count, dtype: int64\n",
      "date\n",
      "2020    330\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Group the data by year and count the number of posts in each year for specified stocks\n",
    "print(pd.to_datetime(df_news[df_news['stock']=='GOOG']['date']).dt.year.value_counts().sort_index())\n",
    "\n",
    "print(pd.to_datetime(df_news[df_news['stock']=='TSLA']['date']).dt.year.value_counts().sort_index())\n",
    "\n",
    "print(pd.to_datetime(df_news[df_news['stock']=='AAPL']['date']).dt.year.value_counts().sort_index())\n",
    "\n",
    "print(pd.to_datetime(df_news[df_news['stock']=='AMZN']['date']).dt.year.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posts are inconsistently spread across years. This possesses a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Score</th>\n",
       "      <th>URL</th>\n",
       "      <th>Content</th>\n",
       "      <th>Post_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>investing</td>\n",
       "      <td>What is the ONE stock you are most excited abo...</td>\n",
       "      <td>Iama_tomhanks</td>\n",
       "      <td>197</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/2s...</td>\n",
       "      <td>No judging, you dicks.</td>\n",
       "      <td>2015-01-11 16:42:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>investing</td>\n",
       "      <td>NFLX: Buy/Hold/Sell thoughts?</td>\n",
       "      <td>TRA8324</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/2s...</td>\n",
       "      <td>domestic growth is definitely slowing, but can...</td>\n",
       "      <td>2015-01-12 20:48:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>finance</td>\n",
       "      <td>Anyone have the marketing/press documents ISIS...</td>\n",
       "      <td>Warhawk_1</td>\n",
       "      <td>7</td>\n",
       "      <td>https://www.reddit.com/r/finance/comments/2sgr...</td>\n",
       "      <td>Was a doc 80-120 pages long, think it was for ...</td>\n",
       "      <td>2015-01-15 01:02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>investing</td>\n",
       "      <td>http://www.gurufocus.com/stock/AAPL</td>\n",
       "      <td>Novast</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/2s...</td>\n",
       "      <td>I am new to investing in stocks and so far hav...</td>\n",
       "      <td>2015-01-15 15:24:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>finance</td>\n",
       "      <td>Tesla will not be profitable, under generally ...</td>\n",
       "      <td>chocolateolive</td>\n",
       "      <td>85</td>\n",
       "      <td>https://www.reddit.com/r/finance/comments/2sm1...</td>\n",
       "      <td>in the WSJ, Musk said he \"doesn't expect Tesla...</td>\n",
       "      <td>2015-01-16 08:37:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>stocks</td>\n",
       "      <td>Tesla Will Hit 500,000 Deliveries for 2020, An...</td>\n",
       "      <td>coolcomfort123</td>\n",
       "      <td>1620</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/kn48j...</td>\n",
       "      <td>https://www.thestreet.com/investing/tesla-tsla...</td>\n",
       "      <td>2020-12-30 15:29:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>economy</td>\n",
       "      <td>What do you think, could tesla stock collapse ...</td>\n",
       "      <td>jumplineg</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/economy/comments/knlf...</td>\n",
       "      <td>&amp;#x200B;\\n\\nhttps://preview.redd.it/zuju24i54h...</td>\n",
       "      <td>2020-12-31 07:20:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>stocks</td>\n",
       "      <td>Tesla Short Sellers Lost $38 Billion in 2020 a...</td>\n",
       "      <td>coolcomfort123</td>\n",
       "      <td>2498</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/knqco...</td>\n",
       "      <td>https://www.bloombergquint.com/business/tesla-...</td>\n",
       "      <td>2020-12-31 13:52:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>AAPL is the 2021 Play</td>\n",
       "      <td>thinkclay</td>\n",
       "      <td>87</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>Missed out on the TSLA run in 2020? Aww, that’...</td>\n",
       "      <td>2020-12-31 17:11:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>investing</td>\n",
       "      <td>Why the $TSLA bubble will not burst?</td>\n",
       "      <td>BenDoverR8Now</td>\n",
       "      <td>20</td>\n",
       "      <td>https://www.reddit.com/r/investing/comments/kn...</td>\n",
       "      <td>A correction (\\~-20%) can happen, but the bubb...</td>\n",
       "      <td>2020-12-31 22:12:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1579 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Query       Subreddit                                              Title  \\\n",
       "0     MSFT       investing  What is the ONE stock you are most excited abo...   \n",
       "1     NFLX       investing                      NFLX: Buy/Hold/Sell thoughts?   \n",
       "2     GOOG         finance  Anyone have the marketing/press documents ISIS...   \n",
       "3     AAPL       investing                http://www.gurufocus.com/stock/AAPL   \n",
       "4     TSLA         finance  Tesla will not be profitable, under generally ...   \n",
       "...    ...             ...                                                ...   \n",
       "1574  TSLA          stocks  Tesla Will Hit 500,000 Deliveries for 2020, An...   \n",
       "1575  GOOG         economy  What do you think, could tesla stock collapse ...   \n",
       "1576  TSLA          stocks  Tesla Short Sellers Lost $38 Billion in 2020 a...   \n",
       "1577  AAPL  wallstreetbets                              AAPL is the 2021 Play   \n",
       "1578  TSLA       investing               Why the $TSLA bubble will not burst?   \n",
       "\n",
       "              Author  Score  \\\n",
       "0      Iama_tomhanks    197   \n",
       "1            TRA8324      0   \n",
       "2          Warhawk_1      7   \n",
       "3             Novast      0   \n",
       "4     chocolateolive     85   \n",
       "...              ...    ...   \n",
       "1574  coolcomfort123   1620   \n",
       "1575       jumplineg      0   \n",
       "1576  coolcomfort123   2498   \n",
       "1577       thinkclay     87   \n",
       "1578   BenDoverR8Now     20   \n",
       "\n",
       "                                                    URL  \\\n",
       "0     https://www.reddit.com/r/investing/comments/2s...   \n",
       "1     https://www.reddit.com/r/investing/comments/2s...   \n",
       "2     https://www.reddit.com/r/finance/comments/2sgr...   \n",
       "3     https://www.reddit.com/r/investing/comments/2s...   \n",
       "4     https://www.reddit.com/r/finance/comments/2sm1...   \n",
       "...                                                 ...   \n",
       "1574  https://www.reddit.com/r/stocks/comments/kn48j...   \n",
       "1575  https://www.reddit.com/r/economy/comments/knlf...   \n",
       "1576  https://www.reddit.com/r/stocks/comments/knqco...   \n",
       "1577  https://www.reddit.com/r/wallstreetbets/commen...   \n",
       "1578  https://www.reddit.com/r/investing/comments/kn...   \n",
       "\n",
       "                                                Content            Post_Date  \n",
       "0                                No judging, you dicks.  2015-01-11 16:42:11  \n",
       "1     domestic growth is definitely slowing, but can...  2015-01-12 20:48:03  \n",
       "2     Was a doc 80-120 pages long, think it was for ...  2015-01-15 01:02:27  \n",
       "3     I am new to investing in stocks and so far hav...  2015-01-15 15:24:00  \n",
       "4     in the WSJ, Musk said he \"doesn't expect Tesla...  2015-01-16 08:37:12  \n",
       "...                                                 ...                  ...  \n",
       "1574  https://www.thestreet.com/investing/tesla-tsla...  2020-12-30 15:29:29  \n",
       "1575  &#x200B;\\n\\nhttps://preview.redd.it/zuju24i54h...  2020-12-31 07:20:47  \n",
       "1576  https://www.bloombergquint.com/business/tesla-...  2020-12-31 13:52:20  \n",
       "1577  Missed out on the TSLA run in 2020? Aww, that’...  2020-12-31 17:11:40  \n",
       "1578  A correction (\\~-20%) can happen, but the bubb...  2020-12-31 22:12:10  \n",
       "\n",
       "[1579 rows x 8 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>writer</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>550441509175443456</td>\n",
       "      <td>VisualStockRSRC</td>\n",
       "      <td>2015-01-01 00:00:57</td>\n",
       "      <td>lx21 made $10,008  on $AAPL -Check it out! htt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:00:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>550441672312512512</td>\n",
       "      <td>KeralaGuy77</td>\n",
       "      <td>2015-01-01 00:01:36</td>\n",
       "      <td>Insanity of today weirdo massive selling. $aap...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>550441732014223360</td>\n",
       "      <td>DozenStocks</td>\n",
       "      <td>2015-01-01 00:01:50</td>\n",
       "      <td>S&amp;P100 #Stocks Performance $HD $LOW $SBUX $TGT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:01:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>550442977802207232</td>\n",
       "      <td>ShowDreamCar</td>\n",
       "      <td>2015-01-01 00:06:47</td>\n",
       "      <td>$GM $TSLA: Volkswagen Pushes 2014 Record Recal...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:06:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>550443807834402816</td>\n",
       "      <td>i_Know_First</td>\n",
       "      <td>2015-01-01 00:10:05</td>\n",
       "      <td>Swing Trading: Up To 8.91% Return In 14 Days h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:10:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336440</th>\n",
       "      <td>1212159838882533376</td>\n",
       "      <td>ShortingIsFun</td>\n",
       "      <td>2019-12-31 23:53:21</td>\n",
       "      <td>In 2020 I may start Tweeting out positive news...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>23:53:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336441</th>\n",
       "      <td>1212160015332728833</td>\n",
       "      <td>Commuternyc</td>\n",
       "      <td>2019-12-31 23:54:03</td>\n",
       "      <td>Patiently Waiting for the no twitter sitter tw...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>23:54:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336442</th>\n",
       "      <td>1212160410692046849</td>\n",
       "      <td>MoriaCrypto</td>\n",
       "      <td>2019-12-31 23:55:37</td>\n",
       "      <td>I don't discriminate. I own both $aapl and $ms...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>23:55:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336443</th>\n",
       "      <td>1212160410692046849</td>\n",
       "      <td>MoriaCrypto</td>\n",
       "      <td>2019-12-31 23:55:37</td>\n",
       "      <td>I don't discriminate. I own both $aapl and $ms...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>23:55:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336444</th>\n",
       "      <td>1212160477159206912</td>\n",
       "      <td>treabase</td>\n",
       "      <td>2019-12-31 23:55:53</td>\n",
       "      <td>$AAPL #patent 10,522,475 Vertical interconnect...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>23:55:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4336445 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tweet_id           writer           post_date  \\\n",
       "0         550441509175443456  VisualStockRSRC 2015-01-01 00:00:57   \n",
       "1         550441672312512512      KeralaGuy77 2015-01-01 00:01:36   \n",
       "2         550441732014223360      DozenStocks 2015-01-01 00:01:50   \n",
       "3         550442977802207232     ShowDreamCar 2015-01-01 00:06:47   \n",
       "4         550443807834402816     i_Know_First 2015-01-01 00:10:05   \n",
       "...                      ...              ...                 ...   \n",
       "4336440  1212159838882533376    ShortingIsFun 2019-12-31 23:53:21   \n",
       "4336441  1212160015332728833      Commuternyc 2019-12-31 23:54:03   \n",
       "4336442  1212160410692046849      MoriaCrypto 2019-12-31 23:55:37   \n",
       "4336443  1212160410692046849      MoriaCrypto 2019-12-31 23:55:37   \n",
       "4336444  1212160477159206912         treabase 2019-12-31 23:55:53   \n",
       "\n",
       "                                                      body  comment_num  \\\n",
       "0        lx21 made $10,008  on $AAPL -Check it out! htt...            0   \n",
       "1        Insanity of today weirdo massive selling. $aap...            0   \n",
       "2        S&P100 #Stocks Performance $HD $LOW $SBUX $TGT...            0   \n",
       "3        $GM $TSLA: Volkswagen Pushes 2014 Record Recal...            0   \n",
       "4        Swing Trading: Up To 8.91% Return In 14 Days h...            0   \n",
       "...                                                    ...          ...   \n",
       "4336440  In 2020 I may start Tweeting out positive news...            0   \n",
       "4336441  Patiently Waiting for the no twitter sitter tw...            0   \n",
       "4336442  I don't discriminate. I own both $aapl and $ms...            1   \n",
       "4336443  I don't discriminate. I own both $aapl and $ms...            1   \n",
       "4336444  $AAPL #patent 10,522,475 Vertical interconnect...            0   \n",
       "\n",
       "         retweet_num  like_num ticker_symbol        date      time  \n",
       "0                  0         1          AAPL  2015-01-01  00:00:57  \n",
       "1                  0         0          AAPL  2015-01-01  00:01:36  \n",
       "2                  0         0          AMZN  2015-01-01  00:01:50  \n",
       "3                  0         1          TSLA  2015-01-01  00:06:47  \n",
       "4                  0         1          AAPL  2015-01-01  00:10:05  \n",
       "...              ...       ...           ...         ...       ...  \n",
       "4336440            0         1          TSLA  2019-12-31  23:53:21  \n",
       "4336441            0         5          TSLA  2019-12-31  23:54:03  \n",
       "4336442            0         1          AAPL  2019-12-31  23:55:37  \n",
       "4336443            0         1          MSFT  2019-12-31  23:55:37  \n",
       "4336444            0         0          AAPL  2019-12-31  23:55:53  \n",
       "\n",
       "[4336445 rows x 10 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
